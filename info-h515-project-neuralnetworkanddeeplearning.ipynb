{
 "cells": [
  {
   "source": [
    "### Author : Kubam Ivo\n",
    "### Purpose: This notebook covers objectives 1 and 5 of the project assignment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary modules\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\ivomb\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:100.)\n  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# initialising hyper paramenters\n",
    "BATCH = 2 #the number of data samples propagated through the network before the parameters are updated\n",
    "EPOCHS = 10 #the number times to iterate over the dataset\n",
    "\n",
    "LR = 0.01\n",
    "IM_SIZE = 32\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # checking if GPU is available if not use CPU\n",
    "torch.set_num_threads(1) # number of threads to one\n",
    "TRAIN_DIR = \"C:\\\\Users\\\\ivomb\\\\OneDrive\\\\Msc Data Science\\\\Second-Semester\\\\INFO-H-515-BigData-Distributed-Data-Management-and-Scalable-Analytics\\\\Practical_Sessions\\\\mini_herbarium\\\\train\\\\\"    # training source\n",
    "Test_Dir = \"C:\\\\Users\\\\ivomb\\\\Downloads\\\\test\\\\\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading train images metadata\n",
    "with open(TRAIN_DIR + 'metadata.json', \"r\", encoding=\"ISO-8859-1\") as file:\n",
    "    train = json.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing image file name and their annotations as pandas dataframe\n",
    "train_img = pd.DataFrame(train['images'])\n",
    "train_ann = pd.DataFrame(train['annotations']).drop(columns='image_id')\n",
    "train_df = train_img.merge(train_ann, on='id') # merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   file_name  height       id  license  width  category_id  \\\n",
       "0   images/000/01/404873.jpg    1000   404873        0    680            1   \n",
       "1  images/000/01/1515603.jpg    1000  1515603        0    680            1   \n",
       "2  images/000/00/1433074.jpg    1000  1433074        0    660            0   \n",
       "3  images/000/01/1104517.jpg    1000  1104517        0    680            1   \n",
       "4  images/000/01/1948744.jpg    1000  1948744        0    680            1   \n",
       "\n",
       "   institution_id  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>file_name</th>\n      <th>height</th>\n      <th>id</th>\n      <th>license</th>\n      <th>width</th>\n      <th>category_id</th>\n      <th>institution_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>images/000/01/404873.jpg</td>\n      <td>1000</td>\n      <td>404873</td>\n      <td>0</td>\n      <td>680</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>images/000/01/1515603.jpg</td>\n      <td>1000</td>\n      <td>1515603</td>\n      <td>0</td>\n      <td>680</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>images/000/00/1433074.jpg</td>\n      <td>1000</td>\n      <td>1433074</td>\n      <td>0</td>\n      <td>660</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>images/000/01/1104517.jpg</td>\n      <td>1000</td>\n      <td>1104517</td>\n      <td>0</td>\n      <td>680</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>images/000/01/1948744.jpg</td>\n      <td>1000</td>\n      <td>1948744</td>\n      <td>0</td>\n      <td>680</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 547
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CL = len(train_df['category_id'].value_counts()) # requesting number of classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_df['file_name'].values, train_df['category_id'].values # separating features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transform = transforms.Compose(\n",
    "    [\n",
    "    transforms.Resize((IM_SIZE, IM_SIZE)), # Resize the input image to the given size \n",
    "    transforms.ToTensor(), # ToTensor converts a PIL image or NumPy ndarray into a FloatTensor and scales the image’s pixel intensity values in the range [0., 1.]\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]) # Normalize a tensor image with mean and standard deviation. mean[1],...,mean[n]) and std: (std[1],..,std[n]) for n channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a custom dataset for image files\n",
    "#The Dataset retrieves our dataset’s features and labels one sample at a time\n",
    "class GetData(Dataset):\n",
    "    \n",
    "    def __init__(self, Dir, FNames, Labels, Transform): # initialising class attributes\n",
    "        self.dir = Dir\n",
    "        self.fnames = FNames\n",
    "        self.transform = Transform\n",
    "        self.labels = Labels         \n",
    "        \n",
    "    def __len__(self): # returns number of samples\n",
    "        return len(self.fnames)\n",
    "\n",
    "    def __getitem__(self, index):        # retrives image sample\n",
    "        x = Image.open(os.path.join(self.dir, self.fnames[index])) #opening images with pilow\n",
    "        # transform\n",
    "        return self.transform(x), self.labels[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = GetData(TRAIN_DIR, X_train, y_train, Transform) # training dataset\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH, shuffle=True) # preparing data for taining\n",
    "\n",
    "testset = GetData(TRAIN_DIR, X_test, y_test, Transform) # test dataset\n",
    "testloader = DataLoader(testset, batch_size=1, shuffle=True) # preparing data for test\n",
    "\n",
    "# While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval."
   ]
  },
  {
   "source": [
    "### Modelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model = torchvision.models.vgg11(num_classes=NUM_CL) # instantiating the resnet34 neural network model\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, NUM_CL)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "\n",
    "# Choose 1 optimiser: hold the current model state and will update the parameters based on the computed gradients.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR) # Adam optimisation\n",
    "#optimizer = torch.optim.Adagrad(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 | Loss: 3.5604\n",
      "Epoch: 1 | Loss: 1.8620\n",
      "Epoch: 2 | Loss: 1.7588\n",
      "Epoch: 3 | Loss: 1.6412\n",
      "Epoch: 4 | Loss: 1.1656\n",
      "Epoch: 5 | Loss: 1.4680\n",
      "Epoch: 6 | Loss: 0.8917\n",
      "Epoch: 7 | Loss: 0.6738\n",
      "Epoch: 8 | Loss: 0.7386\n",
      "Epoch: 9 | Loss: 0.5186\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training Mode\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss = 0.0\n",
    "    correct = 0\n",
    "    model = model.train()\n",
    "\n",
    "    for i, (images, labels) in enumerate(trainloader):        \n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)       \n",
    "        logits = model(images)       \n",
    "        loss = criterion(logits, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        tr_loss += loss.detach().item()        \n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f'%(epoch, tr_loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0 | Accuracy: 0.5000\n",
      "Epoch: 1 | Accuracy: 0.5000\n",
      "Epoch: 2 | Accuracy: 0.5000\n",
      "Epoch: 3 | Accuracy: 0.5000\n",
      "Epoch: 4 | Accuracy: 0.5000\n",
      "Epoch: 5 | Accuracy: 0.5000\n",
      "Epoch: 6 | Accuracy: 0.5000\n",
      "Epoch: 7 | Accuracy: 0.5000\n",
      "Epoch: 8 | Accuracy: 0.5000\n",
      "Epoch: 9 | Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Testing mode\n",
    "for epoch in range(EPOCHS):\n",
    "    tr_loss = 0.0\n",
    "    correct = 0\n",
    "    model = model.eval()\n",
    "\n",
    "    for i, (images, labels) in enumerate(testloader):        \n",
    "        images = images.to(DEVICE)\n",
    "        \n",
    "        labels = labels.to(DEVICE)         \n",
    "\n",
    "        # Get the predictions\n",
    "        out = model(images)\n",
    "        # Calculate the accuracy\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        \n",
    "\n",
    "        if labels == predicted:\n",
    "            correct += torch.sum(labels==predicted).item()\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Accuracy: %.4f'%(epoch, correct/len(testloader.dataset) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "source": [
    "## Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 32, 32])"
      ]
     },
     "metadata": {},
     "execution_count": 560
    }
   ],
   "source": [
    "# Loading the saved model\n",
    "model_1 = torch.load('model.pth')\n",
    "\n",
    "#Sample image for prediction\n",
    "x = Transform(Image.open(\"C:\\\\Users\\\\ivomb\\\\OneDrive\\\\Msc Data Science\\\\Second-Semester\\\\INFO-H-515-BigData-Distributed-Data-Management-and-Scalable-Analytics\\\\Practical_Sessions\\\\mini_herbarium\\\\train\\\\images\\\\000\\\\01\\\\230965.jpg\"))\n",
    "\n",
    "x= x.unsqueeze(0) \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 561
    }
   ],
   "source": [
    "#current class\n",
    "train_df[\"category_id\"][train_df['file_name'] == \"images/000/01/230965.jpg\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "output = model_1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the class with the highest prediction probability\n",
    "_, predicted = torch.max(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "metadata": {},
     "execution_count": 564
    }
   ],
   "source": [
    "#predicted class\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Two\n",
    "x2 =  Transform(Image.open(\"C:\\\\Users\\\\ivomb\\\\OneDrive\\\\Msc Data Science\\\\Second-Semester\\\\INFO-H-515-BigData-Distributed-Data-Management-and-Scalable-Analytics\\\\Practical_Sessions\\\\mini_herbarium\\\\train\\\\images\\\\000\\\\00\\\\1360648.jpg\"))\n",
    "x2= x2.unsqueeze(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5    0\n",
       "Name: category_id, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 566
    }
   ],
   "source": [
    "#current class\n",
    "train_df[\"category_id\"][train_df['file_name'] == \"images/000/00/1360648.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "output = model_1(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the class with the highest prediction probability\n",
    "_, predicted = torch.max(output, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1])"
      ]
     },
     "metadata": {},
     "execution_count": 569
    }
   ],
   "source": [
    "#predicted class\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python383jvsc74a57bd0ba7d381a7320e8ab0820bd1b62e94521294792d6ec93168b850842f0e445242e",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}